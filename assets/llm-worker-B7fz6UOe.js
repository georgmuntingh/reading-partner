(function(){"use strict";let m=null,c=null,y=!1,g=!1,f=!1,w=null;self.addEventListener("unhandledrejection",s=>{var e;const t=((e=s.reason)==null?void 0:e.message)??String(s.reason);(t.includes("Device")&&t.includes("lost")||t.includes("mapAsync"))&&self.postMessage({type:"error",error:"GPU device lost — your GPU may have run out of memory or timed out. Try a smaller model or restart the browser."})});async function G(){if(typeof navigator>"u"||!navigator.gpu)return!1;try{return await navigator.gpu.requestAdapter()!==null}catch{return!1}}async function U(s){return s==="webgpu"?"webgpu":s==="wasm"?"wasm":await G()?"webgpu":"wasm"}function P(s,t){let e=t.buf+s;t.buf="";let i="";for(;e.length>0;)if(t.inThink){const r=e.indexOf("</think>");if(r===-1){const o=Math.min(e.length,7);t.buf=e.slice(e.length-o),e=""}else t.inThink=!1,e=e.slice(r+8).replace(/^\n/,"")}else{const r=e.indexOf("<think>");if(r===-1){const o=Math.min(e.length,6);i+=e.slice(0,e.length-o),t.buf=e.slice(e.length-o),e=""}else i+=e.slice(0,r),t.inThink=!0,e=e.slice(r+7)}return i}function L(s){if(s.inThink)return s.buf="","";const t=s.buf;return s.buf="",t}async function I(s){if(y)return;y=!0;const{model:t="HuggingFaceTB/SmolLM2-360M-Instruct",device:e="auto",dtype:i="q4f16",chatOptions:r=null}=s;w=r;try{self.postMessage({type:"loading",progress:{status:"Loading transformers.js library..."}});const o=await import("https://cdn.jsdelivr.net/npm/@huggingface/transformers@3");o.env.allowLocalModels=!1;const a=await U(e);self.postMessage({type:"loading",progress:{status:`Loading LLM model (${a}, ${i})...`}}),c=await o.AutoTokenizer.from_pretrained(t,{progress_callback:n=>{n.status==="progress"&&self.postMessage({type:"loading",progress:{status:`Downloading ${n.file}`,file:n.file,loaded:n.loaded,total:n.total,progress:n.progress}})}}),m=await o.AutoModelForCausalLM.from_pretrained(t,{device:a,dtype:i,progress_callback:n=>{n.status==="progress"&&self.postMessage({type:"loading",progress:{status:`Downloading ${n.file}`,file:n.file,loaded:n.loaded,total:n.total,progress:n.progress}})}}),y=!1,self.postMessage({type:"ready",info:{model:t,device:a,dtype:i}})}catch(o){y=!1;let a=o.message??String(o);a.includes("Aborted")?a=`Model session failed to start (dtype "${i}" may not be supported on this GPU). Try a different model.`:(a.includes("Device")&&a.includes("lost")||a.includes("mapAsync"))&&(a="GPU device lost while loading the model — your GPU may have run out of memory. Try a smaller model."),self.postMessage({type:"error",error:a})}}async function x(s){if(!m||!c){self.postMessage({type:"error",error:"Model not loaded"});return}if(g){self.postMessage({type:"error",error:"Already generating"});return}g=!0,f=!1;const{messages:t,max_new_tokens:e=512,temperature:i=.7,do_sample:r=!0,top_p:o=.9,repetition_penalty:a=1.1}=s;try{const{noThink:n,...u}=w||{};let M=t;n&&(M=t.map((l,h)=>h===t.length-1&&l.role==="user"?{...l,content:l.content+`
/no_think`}:l));const p=c.apply_chat_template(M,{add_generation_prompt:!0,return_tensor:!1,...u}),{Tensor:T}=await import("https://cdn.jsdelivr.net/npm/@huggingface/transformers@3"),$=new T("int64",BigInt64Array.from(p.map(BigInt)),[1,p.length]),O=new T("int64",new BigInt64Array(p.length).fill(1n),[1,p.length]);let B=[],d="",_=0;const v={inThink:!1,buf:""},C=await m.generate({input_ids:$,attention_mask:O,max_new_tokens:e,temperature:r?i:1,do_sample:r,top_p:r?o:void 0,repetition_penalty:a,streamer:{put(l){if(f)return;const k=Array.from(l.flat()).slice(p.length).slice(_);if(_+=k.length,k.length===0)return;B.push(...k);const A=c.decode(k,{skip_special_tokens:!0});if(A){const b=P(A,v);b&&(d+=b,self.postMessage({type:"token",token:b}))}},end(){const l=L(v);l&&(d+=l,self.postMessage({type:"token",token:l}))}}});if(g=!1,f)self.postMessage({type:"aborted",text:d});else{const h=C.tolist()[0].slice(p.length);d=c.decode(h,{skip_special_tokens:!0}),d=d.replace(/<think>[\s\S]*?<\/think>\s*/g,"").trim(),self.postMessage({type:"complete",text:d})}}catch(n){if(g=!1,f)self.postMessage({type:"aborted",text:""});else{let u=n.message??String(n);(u.includes("Device")&&u.includes("lost")||u.includes("mapAsync"))&&(u="GPU device lost during generation — your GPU may have run out of memory or timed out. Try a smaller model."),self.postMessage({type:"error",error:u})}}}function D(){f=!0}function S(){m=null,c=null,g=!1,f=!1,w=null,self.postMessage({type:"unloaded"})}self.onmessage=async s=>{const{type:t,...e}=s.data;switch(t){case"load":await I(e);break;case"generate":await x(e);break;case"abort":D();break;case"unload":S();break;default:console.warn(`[llm-worker] Unknown message type: ${t}`)}}})();
