(function(){"use strict";let d=null,n=null,f=!1,i=!1,r=!1;async function M(){if(typeof navigator>"u"||!navigator.gpu)return!1;try{return await navigator.gpu.requestAdapter()!==null}catch{return!1}}async function k(t){return t==="webgpu"?"webgpu":t==="wasm"?"wasm":await M()?"webgpu":"wasm"}async function _(t){if(f)return;f=!0;const{model:s="HuggingFaceTB/SmolLM2-360M-Instruct",device:l="auto",dtype:p="q4f16"}=t;try{self.postMessage({type:"loading",progress:{status:"Loading transformers.js library..."}});const a=await import("https://cdn.jsdelivr.net/npm/@huggingface/transformers@3");a.env.allowLocalModels=!1;const u=await k(l);self.postMessage({type:"loading",progress:{status:`Loading LLM model (${u}, ${p})...`}}),n=await a.AutoTokenizer.from_pretrained(s,{progress_callback:e=>{e.status==="progress"&&self.postMessage({type:"loading",progress:{status:`Downloading ${e.file}`,file:e.file,loaded:e.loaded,total:e.total,progress:e.progress}})}}),d=await a.AutoModelForCausalLM.from_pretrained(s,{device:u,dtype:p,progress_callback:e=>{e.status==="progress"&&self.postMessage({type:"loading",progress:{status:`Downloading ${e.file}`,file:e.file,loaded:e.loaded,total:e.total,progress:e.progress}})}}),f=!1,self.postMessage({type:"ready",info:{model:s,device:u,dtype:p}})}catch(a){f=!1,self.postMessage({type:"error",error:a.message})}}async function b(t){if(!d||!n){self.postMessage({type:"error",error:"Model not loaded"});return}if(i){self.postMessage({type:"error",error:"Already generating"});return}i=!0,r=!1;const{messages:s,max_new_tokens:l=512,temperature:p=.7,do_sample:a=!0,top_p:u=.9,repetition_penalty:e=1.1}=t;try{const o=n.apply_chat_template(s,{add_generation_prompt:!0,return_tensor:!1}),{Tensor:m}=await import("https://cdn.jsdelivr.net/npm/@huggingface/transformers@3"),A=new m("int64",BigInt64Array.from(o.map(BigInt)),[1,o.length]),I=new m("int64",new BigInt64Array(o.length).fill(1n),[1,o.length]);let L=[],c="";const T=await d.generate({input_ids:A,attention_mask:I,max_new_tokens:l,temperature:a?p:1,do_sample:a,top_p:a?u:void 0,repetition_penalty:e,streamer:{put(w){if(r)return;const g=Array.from(w.flat());L.push(...g);const y=n.decode(g,{skip_special_tokens:!0});y&&(c+=y,self.postMessage({type:"token",token:y}))},end(){}}});if(i=!1,r)self.postMessage({type:"aborted",text:c});else{const g=T.tolist()[0].slice(o.length);c=n.decode(g,{skip_special_tokens:!0}),self.postMessage({type:"complete",text:c})}}catch(o){i=!1,r?self.postMessage({type:"aborted",text:""}):self.postMessage({type:"error",error:o.message})}}function h(){r=!0}function v(){d=null,n=null,i=!1,r=!1,self.postMessage({type:"unloaded"})}self.onmessage=async t=>{const{type:s,...l}=t.data;switch(s){case"load":await _(l);break;case"generate":await b(l);break;case"abort":h();break;case"unload":v();break;default:console.warn(`[llm-worker] Unknown message type: ${s}`)}}})();
