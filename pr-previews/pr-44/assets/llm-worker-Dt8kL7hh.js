(function(){"use strict";let u=null,o=null,f=!1,i=!1,r=!1;async function _(){if(typeof navigator>"u"||!navigator.gpu)return!1;try{return await navigator.gpu.requestAdapter()!==null}catch{return!1}}async function b(t){return t==="webgpu"?"webgpu":t==="wasm"?"wasm":await _()?"webgpu":"wasm"}async function h(t){if(f)return;f=!0;const{model:s="HuggingFaceTB/SmolLM2-360M-Instruct",device:l="auto",dtype:d="q4f16"}=t;try{self.postMessage({type:"loading",progress:{status:"Loading transformers.js library..."}});const a=await import("https://cdn.jsdelivr.net/npm/@huggingface/transformers@3");a.env.allowLocalModels=!1;const p=await b(l);self.postMessage({type:"loading",progress:{status:`Loading LLM model (${p}, ${d})...`}}),o=await a.AutoTokenizer.from_pretrained(s,{progress_callback:e=>{e.status==="progress"&&self.postMessage({type:"loading",progress:{status:`Downloading ${e.file}`,file:e.file,loaded:e.loaded,total:e.total,progress:e.progress}})}}),u=await a.AutoModelForCausalLM.from_pretrained(s,{device:p,dtype:d,progress_callback:e=>{e.status==="progress"&&self.postMessage({type:"loading",progress:{status:`Downloading ${e.file}`,file:e.file,loaded:e.loaded,total:e.total,progress:e.progress}})}}),f=!1,self.postMessage({type:"ready",info:{model:s,device:p,dtype:d}})}catch(a){f=!1,self.postMessage({type:"error",error:a.message})}}async function T(t){if(!u||!o){self.postMessage({type:"error",error:"Model not loaded"});return}if(i){self.postMessage({type:"error",error:"Already generating"});return}i=!0,r=!1;const{messages:s,max_new_tokens:l=512,temperature:d=.7,do_sample:a=!0,top_p:p=.9,repetition_penalty:e=1.1}=t;try{const n=o.apply_chat_template(s,{add_generation_prompt:!0,return_tensor:!1}),{Tensor:m}=await import("https://cdn.jsdelivr.net/npm/@huggingface/transformers@3"),I=new m("int64",BigInt64Array.from(n.map(BigInt)),[1,n.length]),L=new m("int64",new BigInt64Array(n.length).fill(1n),[1,n.length]);let x=[],c="",w=0;const G=await u.generate({input_ids:I,attention_mask:L,max_new_tokens:l,temperature:a?d:1,do_sample:a,top_p:a?p:void 0,repetition_penalty:e,streamer:{put(k){if(r)return;const g=Array.from(k.flat()).slice(n.length).slice(w);if(w+=g.length,g.length===0)return;x.push(...g);const y=o.decode(g,{skip_special_tokens:!0});y&&(c+=y,self.postMessage({type:"token",token:y}))},end(){}}});if(i=!1,r)self.postMessage({type:"aborted",text:c});else{const M=G.tolist()[0].slice(n.length);c=o.decode(M,{skip_special_tokens:!0}),self.postMessage({type:"complete",text:c})}}catch(n){i=!1,r?self.postMessage({type:"aborted",text:""}):self.postMessage({type:"error",error:n.message})}}function v(){r=!0}function A(){u=null,o=null,i=!1,r=!1,self.postMessage({type:"unloaded"})}self.onmessage=async t=>{const{type:s,...l}=t.data;switch(s){case"load":await h(l);break;case"generate":await T(l);break;case"abort":v();break;case"unload":A();break;default:console.warn(`[llm-worker] Unknown message type: ${s}`)}}})();
